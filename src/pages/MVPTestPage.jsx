import React, { useState, useEffect, useRef } from 'react';
import * as Transition from '@headlessui/react';
import * as SpeechSDK from 'microsoft-cognitiveservices-speech-sdk';
import { useTranslation } from 'react-i18next';
import Logo from '../components/common/Logo';

const MVPTestPage = () => {
  const { t } = useTranslation();
  const [status, setStatus] = useState('idle'); // idle, connecting, ready, error
  const [messages, setMessages] = useState([]);
  const [inputValue, setInputValue] = useState('');
  const [isTalking, setIsTalking] = useState(false);

  const videoRef = useRef(null);
  const synthesizerRef = useRef(null);
  const chatEndRef = useRef(null);
  const [debugLog, setDebugLog] = useState([]);
  const [webrtcState, setWebrtcState] = useState('new');
  const [iceState, setIceState] = useState('new');
  const [hasVideoTrack, setHasVideoTrack] = useState(false);
  const [hasAudioTrack, setHasAudioTrack] = useState(false);

  const addDebug = (msg) => {
    console.log(`[AVATAR_DEBUG] ${msg}`);
    setDebugLog(prev => [...prev.slice(-4), msg]);
  };

  useEffect(() => {
    // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
    chatEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const initAvatar = async () => {
    if (synthesizerRef.current) return;

    setStatus('connecting');
    try {
      // 1. ç¯å¢ƒè¯Šæ–­
      console.log('Secure Context:', window.isSecureContext);
      console.log('RTCPeerConnection:', typeof window.RTCPeerConnection !== 'undefined');

      if (!window.isSecureContext && window.location.hostname !== 'localhost' && window.location.hostname !== '127.0.0.1') {
        throw new Error('WebRTC ä»…å¯åœ¨å®‰å…¨ä¸Šä¸‹æ–‡ (HTTPS æˆ– localhost/127.0.0.1) ä¸­è¿è¡Œã€‚');
      }

      // 1. è·å– Token å’Œ ICE æœåŠ¡å™¨
      const [tokenRes, iceRes] = await Promise.all([
        fetch('/api/speech-token'),
        fetch('/api/ice-servers')
      ]);

      if (!tokenRes.ok || !iceRes.ok) {
        throw new Error('æ— æ³•è¿æ¥åˆ°éŸ³è§†é¢‘èº«ä»½éªŒè¯æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–åç«¯ã€‚');
      }

      const { token, region } = await tokenRes.json();
      const iceServers = await iceRes.json();

      // 3. é…ç½® Speech
      const speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, region);
      speechConfig.speechSynthesisLanguage = "zh-CN";
      speechConfig.speechSynthesisVoiceName = "zh-CN-XiaoxiaoNeural";

      // 4. é…ç½® Avatar
      const avatarConfig = new SpeechSDK.AvatarConfig("lisa", "graceful");

      // 5. åˆ›å»ºåˆæˆå™¨
      synthesizerRef.current = new SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);

      // é‡è¦ï¼šç»‘å®šè§†é¢‘å…ƒç´ ç»™ SDK
      if (videoRef.current) {
        synthesizerRef.current.videoElement = videoRef.current;
      }

      // 6. å‡†å¤‡ WebRTC è¿æ¥ (ä½¿ç”¨ ICE æœåŠ¡å™¨)
      // Azure è¿”å›æ ¼å¼: { Urls: [...], Username: "...", Password: "..." }
      addDebug(`ICE from Azure: ${JSON.stringify(iceServers).substring(0, 80)}...`);

      const rtcIceServers = iceServers.Urls ? [{
        urls: iceServers.Urls,
        username: iceServers.Username,
        credential: iceServers.Password
      }] : [];

      addDebug(`Using ${rtcIceServers.length} ICE server(s)`);
      const peerConnection = new RTCPeerConnection({
        iceServers: rtcIceServers
      });

      // é…ç½®ç›‘å¬éŸ³è§†é¢‘æµ
      peerConnection.ontrack = (e) => {
        addDebug(`Track received: ${e.track.kind}`);
        if (e.track.kind === 'video') setHasVideoTrack(true);
        if (e.track.kind === 'audio') setHasAudioTrack(true);

        if (videoRef.current && e.streams && e.streams[0]) {
          videoRef.current.srcObject = e.streams[0];
          videoRef.current.play().catch(err => addDebug(`Autoplay blocked: ${err.message}`));
        }
      };

      // ç›‘å¬è¿æ¥çŠ¶æ€
      peerConnection.onconnectionstatechange = () => {
        setWebrtcState(peerConnection.connectionState);
        addDebug(`Conn State: ${peerConnection.connectionState}`);
      };

      peerConnection.oniceconnectionstatechange = () => {
        setIceState(peerConnection.iceConnectionState);
        addDebug(`ICE State: ${peerConnection.iceConnectionState}`);
      };

      // æ³¨æ„ï¼šä¸è¦æ‰‹åŠ¨æ·»åŠ  transceiverï¼Œè®© SDK è‡ªå·±å¤„ç†åª’ä½“åå•†
      // peerConnection.addTransceiver('video', { direction: 'recvonly' });
      // peerConnection.addTransceiver('audio', { direction: 'recvonly' });

      // 7. å»ºç«‹è¿æ¥ (WebRTC)
      addDebug('Starting Avatar session...');
      await synthesizerRef.current.startAvatarAsync(peerConnection);

      addDebug('Avatar Ready!');
      setStatus('ready');
      addBotMessage("æ‚¨å¥½ï¼æˆ‘æ˜¯ UploadSoul çš„æ•°å­—åŠ©æ‰‹ã€‚æˆ‘å·²ç»å‡†å¤‡å¥½ä¸ºæ‚¨æä¾›é™ªä¼´äº†ã€‚");
    } catch (error) {
      addDebug(`Error: ${error.message}`);
      console.error('Detailed Avatar Init Error:', error);
      setStatus('error');
    }
  };

  const addBotMessage = (text) => {
    setMessages(prev => [...prev, { role: 'bot', text }]);
  };

  const addUserMessage = (text) => {
    setMessages(prev => [...prev, { role: 'user', text }]);
  };

  const handleSend = async () => {
    if (!inputValue.trim() || status !== 'ready') return;

    const text = inputValue;
    setInputValue('');
    addUserMessage(text);
    setIsTalking(true);

    try {
      // 1. è·å– GPT å›å¤
      const chatRes = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: text })
      });

      if (!chatRes.ok) {
        throw new Error(`Chat API å“åº”å¼‚å¸¸: ${chatRes.status}`);
      }

      const data = await chatRes.json();
      const reply = data.reply;

      if (!reply) {
        throw new Error('æœªèƒ½ä»å›å¤ä¸­è§£æå‡ºæ–‡å­—ã€‚');
      }

      addBotMessage(reply);

      // 2. è®©æ•°å­—äººè¯´è¯
      if (synthesizerRef.current) {
        console.log('Synthesizing speech for:', reply);
        await synthesizerRef.current.speakTextAsync(reply);
      }
    } catch (error) {
      console.error('Chat Error:', error);
      addBotMessage(`æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨å‡ºäº†ä¸€ç‚¹å°çŠ¶å†µ (${error.message})ï¼Œè¯·ç¨åå†è¯•ã€‚`);
    } finally {
      setIsTalking(false);
    }
  };

  return (
    <div className="min-h-screen bg-[#0A0A0F] text-white flex flex-col pt-20">
      <div className="flex-1 container mx-auto px-4 py-8 flex flex-col md:flex-row gap-8 max-w-7xl">

        {/* å·¦ä¾§ï¼šæ•°å­—äººè§†é¢‘åŒº */}
        <div className="flex-1 bg-[#12121A] rounded-3xl border border-white/5 overflow-hidden relative shadow-2xl flex flex-col">
          <div className="absolute top-6 left-6 z-10">
            <div className="inline-flex items-center gap-2 px-3 py-1.5 rounded-full bg-black/40 backdrop-blur-md border border-white/10">
              <span className={`w-2 h-2 rounded-full ${status === 'ready' ? 'bg-green-500 animate-pulse' : 'bg-amber-500'}`} />
              <span className="text-xs font-medium uppercase tracking-wider">
                {status === 'ready' ? 'å®æ—¶è¿æ¥ä¸­' : 'å‡†å¤‡è¿æ¥'}
              </span>
            </div>
          </div>

          <div className="flex-1 flex items-center justify-center relative">
            {/* è§†é¢‘æ¸²æŸ“å®¹å™¨ */}
            <div id="video-container" className="w-full h-full min-h-[400px] flex items-center justify-center">
              <video
                ref={videoRef}
                className="w-full h-full object-cover"
                playsInline
                autoPlay
                muted={false}
              />

              {status === 'idle' && (
                <button
                  onClick={initAvatar}
                  className="px-8 py-4 bg-amber-500 text-black font-bold rounded-2xl hover:bg-amber-400 transition-all shadow-xl shadow-amber-500/20 active:scale-95"
                >
                  å¯åŠ¨æ•°å­—äººäº¤äº’
                </button>
              )}

              {status === 'connecting' && (
                <div className="flex flex-col items-center gap-4">
                  <div className="w-12 h-12 border-4 border-amber-500 border-t-transparent rounded-full animate-spin"></div>
                  <p className="text-gray-400 animate-pulse font-light tracking-widest">åˆå§‹åŒ–ç¥ç»æ¸²æŸ“...</p>
                </div>
              )}

              {status === 'ready' && (
                <div className="absolute bottom-4 left-4 right-4 flex justify-between items-end z-20">
                  <div className="bg-black/60 backdrop-blur-md p-3 rounded-xl border border-white/10 text-[10px] space-y-1 font-mono">
                    <div className="text-gray-400"># DIAGNOSTICS</div>
                    <div className="flex gap-4">
                      <span>ICE: <b className={iceState === 'connected' || iceState === 'completed' ? 'text-green-400' : 'text-amber-400'}>{iceState}</b></span>
                      <span>VIDEO: <b className={hasVideoTrack ? 'text-green-400' : 'text-red-400'}>{hasVideoTrack ? 'OK' : 'NO'}</b></span>
                      <span>AUDIO: <b className={hasAudioTrack ? 'text-green-400' : 'text-red-400'}>{hasAudioTrack ? 'OK' : 'NO'}</b></span>
                    </div>
                    {debugLog.length > 0 && (
                      <div className="text-[9px] text-gray-500 italic truncate max-w-[200px]">
                        Last: {debugLog[debugLog.length - 1]}
                      </div>
                    )}
                  </div>

                  {!hasVideoTrack && status === 'ready' && (
                    <div className="bg-red-500/20 text-red-400 text-[10px] px-3 py-1 rounded-full animate-pulse border border-red-500/30">
                      ç­‰å¾…åª’ä½“æµ...
                    </div>
                  )}
                </div>
              )}
            </div>
          </div>
        </div>

        {/* å³ä¾§ï¼šèŠå¤©å¯¹è¯åŒº */}
        <div className="w-full md:w-[400px] flex flex-col bg-[#12121A] rounded-3xl border border-white/5 shadow-2xl relative">
          <div className="p-6 border-b border-white/5">
            <h3 className="font-bold flex items-center gap-2 text-amber-500 uppercase tracking-widest text-sm">
              <svg className="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z" />
              </svg>
              èŠå¤©è®°å½•
            </h3>
          </div>

          <div className="flex-1 overflow-y-auto p-6 space-y-6 custom-scrollbar">
            {messages.length === 0 ? (
              <div className="h-full flex flex-col items-center justify-center text-gray-600 text-center px-4">
                <div className="w-16 h-16 rounded-2xl bg-white/5 flex items-center justify-center mb-4">ğŸ’¬</div>
                <p className="text-sm">å°šæœªå¼€å§‹å¯¹è¯ã€‚å¯åŠ¨æ•°å­—äººåå³å¯è¿›è¡Œå®æ—¶äº¤æµã€‚</p>
              </div>
            ) : (
              messages.map((msg, i) => (
                <div key={i} className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                  <div className={`max-w-[85%] rounded-2xl p-4 text-sm leading-relaxed ${msg.role === 'user'
                    ? 'bg-amber-500 text-black font-medium'
                    : 'bg-white/5 text-gray-200 border border-white/10'
                    }`}>
                    {msg.text}
                  </div>
                </div>
              ))
            )}
            <div ref={chatEndRef} />
          </div>

          {/* è¾“å…¥æ¡† */}
          <div className="p-6 bg-black/20 rounded-b-3xl">
            <div className="relative">
              <input
                type="text"
                value={inputValue}
                onChange={(e) => setInputValue(e.target.value)}
                onKeyPress={(e) => e.key === 'Enter' && handleSend()}
                placeholder={status === 'ready' ? "å‘é€æ¶ˆæ¯ç»™æ•°å­—äºº..." : "è¯·å…ˆå¯åŠ¨æ•°å­—äºº..."}
                disabled={status !== 'ready' || isTalking}
                className="w-full bg-gray-900 border border-white/10 rounded-2xl px-5 py-4 text-sm focus:outline-none focus:ring-2 focus:ring-amber-500/50 transition-all placeholder:text-gray-600 disabled:opacity-50"
              />
              <button
                onClick={handleSend}
                disabled={status !== 'ready' || isTalking}
                className="absolute right-3 top-1/2 -translate-y-1/2 p-2 text-amber-500 hover:text-amber-400 disabled:text-gray-600 transition-colors"
              >
                <svg className="w-6 h-6" fill="currentColor" viewBox="0 0 20 20">
                  <path d="M10.894 2.553a1 1 0 00-1.788 0l-7 14a1 1 0 001.169 1.409l5-1.429A1 1 0 009 15.571V11a1 1 0 112 0v4.571a1 1 0 00.725.962l5 1.428a1 1 0 001.17-1.408l-7-14z" />
                </svg>
              </button>
            </div>
          </div>
        </div>

      </div>

      {/* å…¨å±å¯¹è¯æ¨¡å¼çš„åº•éƒ¨æç¤º */}
      <div className="py-4 text-center text-[10px] text-gray-700 uppercase tracking-[0.2em] font-light">
        Powered by Azure AI Speech & GPT-4 API
      </div>
    </div>
  );
};

export default MVPTestPage;